{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET DESCRIPTION\n",
    "\n",
    "Stability of the Grid System\n",
    "\n",
    "Electrical grids require a balance between electricity supply and demand in order to be stable. Conventional systems achieve this balance through demand-driven electricity production. For future grids with a high share of inflexible (i.e., renewable) energy source, the concept of demand response is a promising solution. This implies changes in electricity consumption in relation to electricity price changes. In this work, we’ll build a binary classification model to predict if a grid is stable or unstable using the UCI Electrical Grid Stability Simulated dataset.\n",
    "\n",
    "Dataset: https://archive.ics.uci.edu/ml/datasets/Electrical+Grid+Stability+Simulated+Data+\n",
    "\n",
    "It has 12 primary predictive features and two dependent variables.\n",
    "\n",
    "Predictive features:\n",
    "1.\t'tau1' to 'tau4': the reaction time of each network participant, a real value within the range 0.5 to 10 ('tau1' corresponds to the supplier node, 'tau2' to 'tau4' to the consumer nodes);\n",
    "2.\t'p1' to 'p4': nominal power produced (positive) or consumed (negative) by each network participant, a real value within the range -2.0 to -0.5 for consumers ('p2' to 'p4'). As the total power consumed equals the total power generated, p1 (supplier node) = - (p2 + p3 + p4);\n",
    "3.\t'g1' to 'g4': price elasticity coefficient for each network participant, a real value within the range 0.05 to 1.00 ('g1' corresponds to the supplier node, 'g2' to 'g4' to the consumer nodes; 'g' stands for 'gamma');\n",
    "\n",
    "Dependent variables:\n",
    "1.\t'stab': the maximum real part of the characteristic differential equation root (if positive, the system is linearly unstable; if negative, linearly stable);\n",
    "2.\t'stabf': a categorical (binary) label ('stable' or 'unstable').\n",
    "\n",
    "\n",
    "INSTRUCTIONS:\n",
    "\n",
    "Because of the direct relationship between 'stab' and 'stabf' ('stabf' = 'stable' if 'stab' <= 0, 'unstable' otherwise), 'stab' should be dropped and 'stabf' will remain as the sole dependent variable (binary classification).\n",
    "\n",
    "Split the data into an 80-20 train-test split with a random state of “1”. Use the standard scaler to transform the train set (x_train, y_train) and the test set (x_test). \n",
    "\n",
    "Use scikit learn to train a random forest and extra trees classifier. And use xgboost and lightgbm to train an extreme boosting model and a light gradient boosting model. \n",
    "\n",
    "Use random_state = 1 for training all models and evaluate on the test set. \n",
    "\n",
    "Also, to improve the Extra Trees Classifier, you will use the following parameters (number of estimators, minimum number of samples, minimum number of samples for leaf node and the number of features to consider when looking for the best split) for the hyperparameter grid needed to run a Randomized Cross Validation Search (RandomizedSearchCV). \n",
    "n_estimators = [50, 100, 300, 500, 1000]\n",
    "min_samples_split = [2, 3, 5, 7, 9]\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "max_features = ['auto', 'sqrt', 'log2', None] \n",
    "hyperparameter_grid = {'n_estimators': n_estimators,\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "                       'min_samples_split': min_samples_split,\n",
    "                       'max_features': max_features}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries to be used as Stage C Lessons\n",
    "\n",
    "# Importing useful libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, \\\n",
    "                    LeaveOneOut, KFold, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "import sklearn.utils\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import xgboost\n",
    "import lightgbm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset from URL\n",
    "grid= pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00471/Data_for_UCI_named.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "\n",
       "         p4        g1        g2        g3        g4      stab     stabf  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  unstable  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957    stable  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  unstable  \n",
       "3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  unstable  \n",
       "4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  unstable  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unstable    6380\n",
       "stable      3620\n",
       "Name: stabf, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#our target stabf distribution\n",
    "grid['stabf'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tau1     0\n",
       "tau2     0\n",
       "tau3     0\n",
       "tau4     0\n",
       "p1       0\n",
       "p2       0\n",
       "p3       0\n",
       "p4       0\n",
       "g1       0\n",
       "g2       0\n",
       "g3       0\n",
       "g4       0\n",
       "stab     0\n",
       "stabf    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for null values in the dataset\n",
    "grid.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tau1     float64\n",
       "tau2     float64\n",
       "tau3     float64\n",
       "tau4     float64\n",
       "p1       float64\n",
       "p2       float64\n",
       "p3       float64\n",
       "p4       float64\n",
       "g1       float64\n",
       "g2       float64\n",
       "g3       float64\n",
       "g4       float64\n",
       "stab     float64\n",
       "stabf     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the datatype of the dataset\n",
    "grid.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "\n",
       "         p4        g1        g2        g3        g4     stabf  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  unstable  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760    stable  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  unstable  \n",
       "3 -0.997374  0.446209  0.976744  0.929381  0.362718  unstable  \n",
       "4 -0.554305  0.797110  0.455450  0.656947  0.820923  unstable  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'stab' should be dropped\n",
    "grid.drop(['stab'],axis=1,inplace=True)\n",
    "grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "X = grid.drop(columns = 'stabf')\n",
    "y = grid['stabf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into 80:20 training and testing test with a random_state of 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() # Initializes a StandardScaler object\n",
    "scaled_X_train = scaler.fit_transform(X_train) # Fits and transform the training set\n",
    "scaled_X_test = scaler.transform(X_test) # Transforms the testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that returns the metric score of a test set. The metric can be any of accuracy_score, precision_score, recall_score, f1_score and confusion matrix.¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to be used\n",
    "metrics = {'accuracy_score': accuracy_score, 'precision_score': precision_score, 'recall_score': recall_score, \n",
    "               'f1_score': f1_score, 'confusion_matrix': confusion_matrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function\n",
    "def get_metric_score(metric, ytrue, ypred, neg_pos_label):\n",
    "    ''' This function returns the specified metric score. It only works with classifier metrics.\n",
    "        \n",
    "        Args:   metric (string): the evaluating metric, can be any of accuracy_score, precision_score, recall_score, f1_score, \n",
    "                                 or confusion matrix.\n",
    "                ytrue (array): the true labels\n",
    "                ypred (array): the predicted labels\n",
    "                neg_pos_label (list): a list of the classes you want as the negative and positive label in order \n",
    "                                      of [negative_label, positive_label]\n",
    "                \n",
    "        Return: returns the metric score\n",
    "    '''\n",
    "    \n",
    "    if metric == 'accuracy_score':\n",
    "        return accuracy_score(ytrue, ypred)\n",
    "    \n",
    "    elif metric == 'confusion_matrix':\n",
    "        return confusion_matrix(ytrue, ypred, neg_pos_label)\n",
    "    \n",
    "    else:\n",
    "        return metrics[metric](ytrue, ypred, pos_label=neg_pos_label[1]) # this is done because precision, recall and f1_score\n",
    "                                                                         # takes the same arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a  function that fits a classifier on a training set and prints out the accuracy_score, precision_score, recall_score, f1_score and confusion matrix of the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function\n",
    "def fit_and_score(classifier, xtrain, ytrain, xtest, ytest, neg_pos_label):\n",
    "    ''' This function fits a classifier on a training set and prints out the accuracy_score, precision_score, recall_score, \n",
    "    f1_score and confusion matrix of the testing set.\n",
    "    \n",
    "    Args: classifier (classifier object): the classifier you want to use\n",
    "          xtrain (ndarray): the training features\n",
    "          ytrain (array): the training labels\n",
    "          xtest (ndarray): the testing features\n",
    "          ytest (array): the testing labels\n",
    "          neg_pos_label (list): a list of the classes you want as the negative and positive label in order \n",
    "                                      of [negative_label, positive_label]\n",
    "    '''\n",
    "    classifier.fit(xtrain, ytrain) # fits the classifier\n",
    "    ypred = classifier.predict(xtest) # predicts\n",
    "    \n",
    "    # for each metric in metrics (dictionary earlier defined), print out the metric score.\n",
    "    for metric in metrics:\n",
    "        \n",
    "        # this 'if' block is to ensure that the confusion matrix is properly printed out to improve redability\n",
    "        if metric == 'confusion_matrix':\n",
    "            print()\n",
    "            print('confusion_matrix is:')\n",
    "            print(get_metric_score(metric, ytest, ypred, neg_pos_label))\n",
    "            \n",
    "        else:\n",
    "            print('{} is {}'.format(metric, get_metric_score(metric, ytest, ypred, neg_pos_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['unstable', 'stable']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of our model on different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and testing on RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score is 0.929\n",
      "precision_score is 0.9191176470588235\n",
      "recall_score is 0.8778089887640449\n",
      "f1_score is 0.8979885057471264\n",
      "\n",
      "confusion_matrix is:\n",
      "[[1233   55]\n",
      " [  87  625]]\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(random_state=1)\n",
    "fit_and_score(random_forest, scaled_X_train, y_train, scaled_X_test, y_test, label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and testing on ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score is 0.928\n",
      "precision_score is 0.9409937888198758\n",
      "recall_score is 0.851123595505618\n",
      "f1_score is 0.8938053097345133\n",
      "\n",
      "confusion_matrix is:\n",
      "[[1250   38]\n",
      " [ 106  606]]\n"
     ]
    }
   ],
   "source": [
    "extra_trees = ExtraTreesClassifier(random_state=1)\n",
    "fit_and_score(extra_trees, scaled_X_train, y_train, scaled_X_test, y_test, label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and testing on xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score is 0.9195\n",
      "precision_score is 0.9206106870229007\n",
      "recall_score is 0.8469101123595506\n",
      "f1_score is 0.8822238478419898\n",
      "\n",
      "confusion_matrix is:\n",
      "[[1236   52]\n",
      " [ 109  603]]\n"
     ]
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier(random_state=1)\n",
    "fit_and_score(xgb, scaled_X_train, y_train, scaled_X_test, y_test, label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and testing on lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score is 0.9375\n",
      "precision_score is 0.9297218155197657\n",
      "recall_score is 0.8918539325842697\n",
      "f1_score is 0.910394265232975\n",
      "\n",
      "confusion_matrix is:\n",
      "[[1240   48]\n",
      " [  77  635]]\n"
     ]
    }
   ],
   "source": [
    "lgbm = lightgbm.LGBMClassifier(random_state=1)\n",
    "fit_and_score(lgbm, scaled_X_train, y_train, scaled_X_test, y_test, label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and testing on tuned ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing search space of hyperparameters\n",
    "n_estimators = [50, 100, 300, 500, 1000]\n",
    "min_samples_split = [2, 3, 5, 7, 9]\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "max_features = ['auto', 'sqrt', 'log2', None]\n",
    "\n",
    "# making a dictionary of the grid\n",
    "hyperparameter_grid = {'n_estimators': n_estimators, 'min_samples_leaf': min_samples_leaf,\n",
    "                       'min_samples_split': min_samples_split, 'max_features': max_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_trees2 = ExtraTreesClassifier(random_state=1) # initializes an ExtraTreesClassifier\n",
    "\n",
    "# initializing a RandomizedSearchCV\n",
    "tuned_extra_trees = RandomizedSearchCV(extra_trees2, hyperparameter_grid, random_state=1, verbose=1, n_jobs=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done  50 out of  50 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score is 0.927\n",
      "precision_score is 0.9211309523809523\n",
      "recall_score is 0.8693820224719101\n",
      "f1_score is 0.8945086705202311\n",
      "\n",
      "confusion_matrix is:\n",
      "[[1235   53]\n",
      " [  93  619]]\n"
     ]
    }
   ],
   "source": [
    "fit_and_score(tuned_extra_trees, scaled_X_train, y_train, scaled_X_test, y_test, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
